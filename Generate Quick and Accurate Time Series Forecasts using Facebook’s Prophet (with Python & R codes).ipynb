{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fbprophet import Prophet\n",
    "# Read train and test\n",
    "train = pd.read_csv('Train_SU63ISt.csv')\n",
    "test = pd.read_csv('Test_0qrQsBZ.csv')\n",
    "\n",
    "# Convert to datetime format\n",
    "train['Datetime'] = pd.to_datetime(train.Datetime,format='%d-%m-%Y %H:%M') \n",
    "test['Datetime'] = pd.to_datetime(test.Datetime,format='%d-%m-%Y %H:%M')\n",
    "train['hour'] = train.Datetime.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average hourly fraction\n",
    "hourly_frac = train.groupby(['hour']).mean()/np.sum(train.groupby(['hour']).mean())\n",
    "hourly_frac.drop(['ID'], axis = 1, inplace = True)\n",
    "hourly_frac.columns = ['fraction']\n",
    "\n",
    "\n",
    "# convert to time series from dataframe\n",
    "train.index = train.Datetime\n",
    "train.drop(['ID','hour','Datetime'], axis = 1, inplace = True)\n",
    "\n",
    "daily_train = train.resample('D').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_train['ds'] = daily_train.index\n",
    "daily_train['y'] = daily_train.Count\n",
    "daily_train.drop(['Count'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet(yearly_seasonality = True, seasonality_prior_scale=0.1)\n",
    "m.fit(daily_train)\n",
    "future = m.make_future_dataframe(periods=213)\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hour, day, month and year from both dataframes to merge\n",
    "for df in [test, forecast]:\n",
    "    df['hour'] = df.Datetime.dt.hour\n",
    "    df['day'] = df.Datetime.dt.day\n",
    "    df['month'] = df.Datetime.dt.month\n",
    "    df['year'] = df.Datetime.dt.year\n",
    "\n",
    "# Merge forecasts with given IDs\n",
    "test = pd.merge(test,forecast, on=['day','month','year'], how='left')\n",
    "cols = ['ID','hour','yhat']\n",
    "test_new = test[cols]\n",
    "\n",
    "# Merging hourly average fraction to the test data\n",
    "test_new = pd.merge(test_new, hourly_frac, left_on = ['hour'], right_index=True, how = 'left')\n",
    "# Convert daily aggregate to hourly traffic\n",
    "test_new['Count'] = test_new['yhat'] * test_new['fraction']\n",
    "test_new.drop(['yhat','fraction','hour'],axis = 1, inplace = True)\n",
    "test_new.to_csv('prophet_sub.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(prophet)\n",
    "library(data.table)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "\n",
    "# read data\n",
    "train = fread(\"Train_SU63ISt.csv\")\n",
    "test = fread(\"Test_0qrQsBZ.csv\")\n",
    "\n",
    "# Extract date from the Datetime variable\n",
    "train$Date = as.POSIXct(strptime(train$Datetime, \"%d-%m-%Y\"))\n",
    "test$Date = as.POSIXct(strptime(test$Datetime, \"%d-%m-%Y\"))\n",
    "\n",
    "# Convert 'Datetime' variable from character to date-time format\n",
    "train$Datetime = as.POSIXct(strptime(train$Datetime, \"%d-%m-%Y %H:%M\"))\n",
    "test$Datetime = as.POSIXct(strptime(test$Datetime, \"%d-%m-%Y %H:%M\"))\n",
    "\n",
    "# Aggregate train data day-wise\n",
    "aggr_train = train[,list(Count = sum(Count)), by = Date]\n",
    "\n",
    "# Visualize the data\n",
    "ggplot(aggr_train) + geom_line(aes(Date, Count))\n",
    "\n",
    "# Change column names\n",
    "names(aggr_train) = c(\"ds\", \"y\")\n",
    "\n",
    "# Model building\n",
    "m = prophet(aggr_train)\n",
    "future = make_future_dataframe(m, periods = 213)\n",
    "forecast = predict(m, future)\n",
    "\n",
    "# Visualize forecast\n",
    "plot(m, forecast)\n",
    "\n",
    "# proportion of mean hourly 'Count' based on train data\n",
    "mean_hourly_count = train %>%\n",
    " group_by(hour = hour(train$Datetime)) %>%\n",
    " summarise(mean_count = mean(Count))\n",
    "\n",
    "s = sum(mean_hourly_count$mean_count)\n",
    "mean_hourly_count$count_proportion = mean_hourly_count$mean_count/s\n",
    "\n",
    "# variable to store hourly Count\n",
    "test_count = NULL\n",
    "\n",
    "for(i in 763:nrow(forecast)){\n",
    " test_count = append(test_count, mean_hourly_count$count_proportion * forecast$yhat[i])\n",
    "}\n",
    "\n",
    "test$Count = test_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
